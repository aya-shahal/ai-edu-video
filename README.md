# ğŸ§  AI Educational Video Generator

## ğŸ¯ Problem Statement
Creating high-quality educational videos requires scripting, voice recording, and manual animation â€” a process thatâ€™s time-consuming and expensive.  
This project automates the entire pipeline using **AI models** that generate scripts, synthesize voices, and animate human avatars with lip-sync â€” turning text into an educational video in minutes.

---

## âš™ï¸ Tech Stack

| Component | Purpose | Library / Model |
|------------|----------|----------------|
| **Script Generation** | Automatically writes educational content or explanations | ğŸ¦™ **LLaMA** |
| **Text-to-Speech** | Converts AI-generated script into natural-sounding speech | ğŸ—£ï¸ **Edge-TTS** |
| **Face Detection & Gender Recognition** | Detects face and gender for accurate rendering setup | ğŸ‘¤ **FaceRender** |
| **Lip-Sync Animation** | Generates realistic talking-head animation synced with speech | ğŸ¬ **SadTalker** |

---

## ğŸ§© Architecture Overview

Input Topic  â†’  LLaMA â†’  Script Text  
â†“  
Edge-TTS â†’  Audio (WAV)  
â†“  
FaceRender â†’  Face & Gender Detection  
â†“  
SadTalker â†’  Lip-Synced Video Output  

Final output: a fully generated **AI educational video** with synced facial animation and voice narration.

---

## ğŸš€ How to Run

### 1. Clone the Repository
git clone https://github.com/your-username/ai-educational-video.git  
cd ai-educational-video  

### 2. Create & Activate a Virtual Environment
python -m venv venv  
source venv/bin/activate   # (Linux/macOS)  
venv\Scripts\activate      # (Windows)  

### 3. Install Dependencies
pip install -r requirements.txt  

### 4. Setup SadTalker
SadTalker is used for lip-sync animation. Follow these steps:

# Clone SadTalker repository  
git clone https://github.com/OpenTalker/SadTalker.git  
cd SadTalker  

# Create and activate a virtual environment  
python -m venv venv  
source venv/bin/activate   # (Linux/macOS)  
venv\Scripts\activate      # (Windows)  

# Install required packages  
pip install -r requirements.txt  

# Download checkpoints  
bash scripts/download_models.sh  

Once the models are downloaded successfully, you can integrate SadTalker into your main pipeline.

---

### 5. Run the Full Pipeline
From the main project folder:
python app.py 

### 6. Output
- ğŸ§¾ output/script.txt â€” AI-generated educational script  
- ğŸ”Š output/audio.wav â€” TTS narration  
- ğŸ¥ output/video.mp4 â€” Final lip-synced educational video  

---

## ğŸ”® Future Improvements
- Multi-language voice synthesis  
- Emotion-aware facial animation  
- Background and subtitle generation  
- Integration with educational content APIs  
